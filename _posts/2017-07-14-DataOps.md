---
layout: post
title: A DevOps Approach to Machine Learning
tags: [dataops, devops, machine learning]
bigimg: /img/tensorflow_banner.png
---


DataOps is a subcategory of DevOps in which data engineers and data scientists are added to the scrum.

Data is becoming a key service item. It's becoming necessary to infuse the entire DevOps department

Data engineering skills will be in the team. It is a distinctly different skill than software development. They have to deal with the pragmatic aspects of handling data.

To describe DevOps, I'm going to borrow heavily from wikipedia. DevOps is a software development and delivery process that emphasizes communication and collaboration between product management, software development, and operations professionals. 



The part that everone talks about is the learning part. But most of the effort to ML is logistitcs, not learning. There are very few solutions of the handling the logistics of deploying models into production.  Why is this hard?

Versioning models is much more difficult than versioning software.

The integration of machine learning and containerization is really valuable because they can provide a really clean way to package up what a data scientist produces, so operations can move it around, version control it, and get reproduciblilty in a production environment.



As DevOps is a truly cross-functional mode of working, there is no single "DevOps tool": it is rather a set (or "toolchain") of multiple tools.[15] DevOps tools tend to fit into one or more of these categories, reflective of key aspects of the development and delivery process:[16][17]

Code — code development and review, source code management tools, code merging
 	-DataOps Correlary: model development, model review, model management
 	-vendors: lots. MxNet, Tensorflow, Spark ML, et al.

Build — continuous integration tools, build status
	-DataOps Correlary: n/a

Test — continuous testing tools that provide feedback on business risks
	-DataOps Correlary: automated testing against test data, feedback high deviations across models for retraining. Requires streams + containerization. MapR or Docker + Kafka/Akka.

Package — artifact repository, application pre-deployment staging
	-DataOps Correlary: model optimization, container compilation

Release — change management, release approvals, release automation
	-DataOps Correlary: deploy to production

Configure — infrastructure configuration and management, Infrastructure as Code tools
	-DataOps Correlary: n/a

Monitor — applications performance monitoring, end–user experience
	-DataOps Correlary: A/B testing, ML accuracy, ML speed, feedback high deviations across models for retraining.

Reference: 
https://en.wikipedia.org/wiki/DevOps
https://thenewstack.io/maprs-ted-dunning-intersection-machine-learning-containers/



<br>
<p>Please provide your feedback to this article by adding a comment to <a href="https://github.com/iandow/iandow.github.io/issues/5">https://github.com/iandow/iandow.github.io/issues/5</a>.</p>

<br><br>
<div class="main-explain-area padding-override jumbotron">
  <img src="http://iandow.github.io/img/paypal.png" width="120" style="margin-left: 15px" align="right">
  <p class="margin-override font-override">
  	Did you enjoy the blog? Did you learn something useful? If you would like to support this blog please consider making a small donation. Thanks!</p>
  <br>
  <div id="paypalbtn">
    <a class="btn btn-primary btn" href="https://www.paypal.me/iandownard/3.5">Donate via PayPal</a>
  </div>
</div>
